{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0              1  \\\n",
      "0         Ship      Sunk date   \n",
      "1   Globe Star  27 April 1973   \n",
      "2  HMS Gulland  13 April 1951   \n",
      "3   MV Mtongwe  27 April 1994   \n",
      "\n",
      "                                                   2  \\\n",
      "0                                              Notes   \n",
      "1      A cargo ship that ran aground off Mombasa.[1]   \n",
      "2  A 545-ton Isles-class trawler built for World ...   \n",
      "3  A Likoni and Mombasa route ferry that capsized...   \n",
      "\n",
      "                                                3  \n",
      "0                                     Coordinates  \n",
      "1       4°04′54″S 39°43′12″E﻿ / ﻿4.0818°S 39.72°E  \n",
      "2  04°02′50″S 39°43′57″E﻿ / ﻿4.04722°S 39.73250°E  \n",
      "3                                             NaN  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not compare ['flag'] with block values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e62a883c5474>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m#new_df.columns = ['ship','sunk_date','notes','coordinates']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;31m#new_df= df.reindex(df.index.drop(0)).reset_index(drop=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mship_wreck_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'flag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;31m#ship_wreck_data = new_df.drop(columns = [4,5,6,7,8])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m#ship_wreck_data = ship_wreck_data.dropna()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1595\u001b[0m             res = self._combine_const(other, func,\n\u001b[0;32m   1596\u001b[0m                                       \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1597\u001b[1;33m                                       try_cast=False)\n\u001b[0m\u001b[0;32m   1598\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_combine_const\u001b[1;34m(self, other, func, errors, try_cast)\u001b[0m\n\u001b[0;32m   4774\u001b[0m         new_data = self._data.eval(func=func, other=other,\n\u001b[0;32m   4775\u001b[0m                                    \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4776\u001b[1;33m                                    try_cast=try_cast)\n\u001b[0m\u001b[0;32m   4777\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   3685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3686\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3687\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3581\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, func, other, errors, try_cast, mgr)\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m                 raise TypeError('Could not compare [{other!r}] '\n\u001b[1;32m-> 1437\u001b[1;33m                                 'with block values'.format(other=other))\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m         \u001b[1;31m# transpose if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not compare ['flag'] with block values"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "from splinter import Browser\n",
    "import codecs\n",
    "import pymongo\n",
    "#set path to use splinter\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "#declare url and parser\n",
    "url = \"https://en.wikipedia.org/wiki/Lists_of_shipwrecks\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "soup = bs(html,'html.parser')\n",
    "\n",
    "url = []\n",
    "#find desired data\n",
    "for i in soup.find('ul').findAll('a'):\n",
    "    url.append(i['href'])\n",
    "\n",
    "\n",
    "    #click link to go to country\n",
    "   # browser.click_link_by_partial_href(i['href'])\n",
    "   # browser.back()\n",
    "\n",
    "    #obtain new page html and parse\n",
    "    #html_country = browser.html\n",
    "    #soup_country = bs(html_country,\"html.parser\")\n",
    "\n",
    "    #find all tables\n",
    "    #wikitables = soup.findAll(\"table\", class_ ='wikitable').findall()\n",
    "    #pd.read_html(\"https://en.wikipedia.org\" + i[\"href\"])\n",
    "    #if i > 1:\n",
    "    #     break\n",
    "tables = []\n",
    "for i in url:\n",
    "    tables.append(pd.read_html(\"https://en.wikipedia.org\" + i))\n",
    "\n",
    "#shipwreck_df = pd.DataFrame(tables)\n",
    "\n",
    "# df = tables[0][0]\n",
    "# df.columns = ['ship','sunk_date','notes','coordinates']\n",
    "# print(df.head())\n",
    "\n",
    "df = tables[0][2]\n",
    "#df.columns = ['ship','sunk_date','notes','coordinates']\n",
    "#print(df.head())\n",
    "#df = df.reindex(df.index.drop(0)).reset_index(drop=True)\n",
    "df\n",
    "print(df)\n",
    "\n",
    "unpacklist = [x for table in tables for x in table]\n",
    "new_unpacklist = unpacklist.remove(unpacklist[0])\n",
    "new_df = pd.concat(unpacklist)\n",
    "new_df = pd.DataFrame(unpacklist)\n",
    "#new_df.columns = ['ship','sunk_date','notes','coordinates']\n",
    "#new_df= df.reindex(df.index.drop(0)).reset_index(drop=True)\n",
    "ship_wreck_data = new_df.loc[:, (new_df == 'flag').all()]\n",
    "#ship_wreck_data = new_df.drop(columns = [4,5,6,7,8])\n",
    "#ship_wreck_data = ship_wreck_data.dropna()\n",
    "#ship_wreck_data.columns= ['ship','sunk_date','notes','coordinates']\n",
    "#ship_wreck_data = df.reindex(df.index.drop(0)).reset_index(drop=True)\n",
    "#ship_wreck_data\n",
    "\n",
    "#ship_wreck_data = ship_wreck_data.drop_duplicates()\n",
    "#ship_wreck_data = ship_wreck_data.drop([0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_wreck_data = ship_wreck_data.reset_index(drop=True)\n",
    "#test = ship_wreck_data['coordinates'].str.encode(\"utf-8\")\n",
    "#test  = test.str.decode(\"utf-8\")\n",
    "#test \n",
    "\n",
    "#ship_wreck_data['coordinates'] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_coordinates = []\n",
    "#ship_wreck_data1 = ship_wreck_data.drop([0,74])\n",
    "\n",
    "for coordinate in ship_wreck_data['coordinates']:\n",
    "    if coordinate.find('/')==-1:\n",
    "        print(coordinate)\n",
    "    else:\n",
    "        latlong = coordinate.split('/')[1]\n",
    "        new_latlong = latlong.replace(\"°\",\"\").strip()\n",
    "        lat = new_latlong.split()[0]\n",
    "        long = new_latlong.split()[1]\n",
    "        lat = lat[1:]\n",
    "    \n",
    "        #print(lat[:len(lat)-2])\n",
    "        if lat[len(lat)-1] == 'S':\n",
    "            lat = 0-float(lat[:len(lat)-2])\n",
    "           # print(lat)\n",
    "        else:\n",
    "            lat = lat.strip(\"N\")\n",
    "            #print(lat)\n",
    "        if long[len(long)-1] == 'W':\n",
    "            long = 0-float(long[:len(long)-2])\n",
    "            #print(long)\n",
    "        else:\n",
    "            long = long.strip(\"E\")\n",
    "        #print(long)\n",
    "    clean_coordinates = [lat,long]\n",
    "    print(clean_coordinates)\n",
    "    true_coordinates.append(clean_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert coordinates into dataframe to clean data\n",
    "true_coordinates_df = pd.DataFrame(true_coordinates)\n",
    "true_coordinates_df.columns = ['Latitude', 'Longitude']\n",
    "\n",
    "#drop duplicate values\n",
    "true_coordinates_df =true_coordinates_df.drop_duplicates()\n",
    "\n",
    "#convert true_coordinates_df to a list then into a series so both values will be in one column as coordinates\n",
    "coordinate = true_coordinates_df.values.tolist()\n",
    "coordinate_series = pd.Series(coordinate)\n",
    "\n",
    "#append coordinate_series to coordinate column and drop Nan values\n",
    "ship_wreck_df = ship_wreck_data\n",
    "ship_wreck_df['coordinates'] = coordinate_series\n",
    "ship_wreck_df =ship_wreck_df.dropna()\n",
    "ship_wreck_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to json\n",
    "import json\n",
    "ship_wreck_json = ship_wreck_df.to_json(orient='records')\n",
    "json_format = json.loads(ship_wreck_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "#create mongo database\n",
    "myclient = pymongo.MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "db = myclient['ship_wreck_db']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = db.ship_wreck_data\n",
    "json_data.insert_many(json_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_wreck_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
